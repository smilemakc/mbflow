name: customer-support-ai
version: 1.0.0
description: Intelligent customer support automation with classification, sentiment analysis, and smart routing

triggers:
  - type: webhook
    id: support-webhook
    config:
      path: /api/support/incoming
      method: POST
      schema:
        customer_message: string
        customer_email: string
        ticket_id: string

nodes:
  # Information extraction
  - id: extract-info
    name: Extract Customer Information
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Extract structured information from this customer inquiry"
      output_key: customer_info

  # Classification
  - id: classify-inquiry
    name: Classify Inquiry Type
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Classify this customer inquiry into ONE category: technical, billing, shipping, product, account, or general"
      output_key: inquiry_type

  # Sentiment analysis
  - id: analyze-sentiment
    name: Analyze Customer Sentiment
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Analyze the sentiment: positive, neutral, or negative"
      output_key: sentiment

  # Billing check router
  - id: check-billing
    name: Check if Billing Inquiry
    type: conditional-router
    config:
      input_key: inquiry_type
      routes:
        billing: fetch-account
        default: check-escalation

  # Fetch account for billing
  - id: fetch-account
    name: Fetch Account Status
    type: http-request
    config:
      url: "https://api.example.com/accounts/{{customer_info.order_id}}"
      method: GET
      output_key: account_status

  # Analyze account
  - id: analyze-account
    name: Analyze Account Status
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Determine appropriate action: refund_eligible, payment_issue, subscription_active, account_suspended, or needs_manual_review"
      output_key: account_action

  # Escalation check
  - id: check-escalation
    name: Check Escalation Criteria
    type: script-executor
    config:
      script: |
        const shouldEscalate = (
          (inquiry_type === 'technical' && sentiment === 'negative') ||
          customer_info.urgency === 'high' ||
          account_action === 'needs_manual_review'
        );
        return shouldEscalate ? 'escalate' : 'generate_response';
      output_key: escalation_decision

  # Escalate to human
  - id: escalate
    name: Escalate to Human Agent
    type: http-request
    config:
      url: https://api.example.com/support/escalate
      method: POST
      output_key: escalation_ticket

  # Generate response context
  - id: generate-context
    name: Generate Response Context
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Create structured context for generating a response"
      output_key: response_context

  # Generate response
  - id: generate-response
    name: Generate Customer Response
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Generate a helpful, empathetic customer support response"
      max_tokens: 800
      output_key: generated_response

  # Quality check
  - id: quality-check
    name: Quality Check Response
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Evaluate response quality (1-10) and return pass/fail"
      output_key: quality_score

  # Quality router
  - id: check-quality
    name: Check Quality Score
    type: conditional-router
    config:
      input_key: quality_score.pass
      routes:
        "true": personalize-response
        "false": regenerate-response

  # Regenerate response
  - id: regenerate-response
    name: Regenerate Response with Feedback
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Generate improved response addressing identified issues"
      output_key: regenerated_response

  # Merge responses
  - id: merge-responses
    name: Merge Responses
    type: data-merger
    config:
      strategy: select_first_available
      sources:
        - regenerated_response
        - generated_response
      output_key: final_response_draft

  # Personalize
  - id: personalize-response
    name: Personalize Response
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Add personalization with customer name and context"
      output_key: final_response

  # Generate follow-up
  - id: generate-followup
    name: Generate Follow-up Suggestions
    type: openai-completion
    config:
      model: gpt-4
      prompt: "Suggest follow-up actions based on interaction"
      output_key: follow_up_plan

  # Send response
  - id: send-response
    name: Send Response to Customer
    type: http-request
    config:
      url: https://api.example.com/support/send
      method: POST

  # Log interaction
  - id: log-interaction
    name: Log Interaction
    type: http-request
    config:
      url: https://api.example.com/analytics/log
      method: POST

edges:
  # Parallel initial processing
  - from: extract-info
    to: classify-inquiry
    type: parallel

  - from: extract-info
    to: analyze-sentiment
    type: parallel

  # Join for billing check
  - from: classify-inquiry
    to: check-billing
    type: direct

  - from: analyze-sentiment
    to: check-billing
    type: join

  # Billing path
  - from: check-billing
    to: fetch-account
    type: conditional
    config:
      condition: inquiry_type == 'billing'

  - from: fetch-account
    to: analyze-account
    type: direct

  - from: analyze-account
    to: check-escalation
    type: direct

  # Non-billing path
  - from: check-billing
    to: check-escalation
    type: conditional
    config:
      condition: inquiry_type != 'billing'

  # Escalation branching
  - from: check-escalation
    to: escalate
    type: conditional
    config:
      condition: escalation_decision == 'escalate'

  - from: check-escalation
    to: generate-context
    type: conditional
    config:
      condition: escalation_decision != 'escalate'

  # Response generation
  - from: generate-context
    to: generate-response
    type: direct

  - from: generate-response
    to: quality-check
    type: direct

  - from: quality-check
    to: check-quality
    type: direct

  # Quality branching
  - from: check-quality
    to: merge-responses
    type: conditional
    config:
      condition: quality_score.pass == true

  - from: check-quality
    to: regenerate-response
    type: conditional
    config:
      condition: quality_score.pass == false

  - from: regenerate-response
    to: merge-responses
    type: direct

  # Finalization
  - from: merge-responses
    to: personalize-response
    type: direct

  # Parallel final steps
  - from: personalize-response
    to: generate-followup
    type: parallel

  - from: personalize-response
    to: send-response
    type: parallel

  # Join for logging
  - from: generate-followup
    to: log-interaction
    type: join

  - from: send-response
    to: log-interaction
    type: join
